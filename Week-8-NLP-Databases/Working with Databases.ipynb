{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access a Database with Python - Iris Dataset\n",
    "\n",
    "The Iris dataset is a popular dataset especially in the Machine Learning community, it is a set of features of 50  Iris flowers and their classification into 3 species.\n",
    "It is often used to introduce classification Machine Learning algorithms.\n",
    "\n",
    "First let's download the dataset in `SQLite` format from Kaggle:\n",
    "\n",
    "<https://www.kaggle.com/uciml/iris/>\n",
    "\n",
    "Download `database.sqlite` and save it in the `data/iris` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img   src=\"https://upload.wikimedia.org/wikipedia/commons/4/49/Iris_germanica_%28Purple_bearded_Iris%29%2C_Wakehurst_Place%2C_UK_-_Diliff.jpg\" alt=\"Iris germanica (Purple bearded Iris), Wakehurst Place, UK - Diliff.jpg\" height=\"145\" width=\"114\"></p>\n",
    "\n",
    "<p><br> From <a href=\"https://commons.wikimedia.org/wiki/File:Iris_germanica_(Purple_bearded_Iris),_Wakehurst_Place,_UK_-_Diliff.jpg#/media/File:Iris_germanica_(Purple_bearded_Iris),_Wakehurst_Place,_UK_-_Diliff.jpg\">Wikimedia</a>, by <a href=\"//commons.wikimedia.org/wiki/User:Diliff\" title=\"User:Diliff\">Diliff</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, <a href=\"http://creativecommons.org/licenses/by-sa/3.0\" title=\"Creative Commons Attribution-Share Alike 3.0\">CC BY-SA 3.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=33037509\">Link</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary machine learning libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's check that the sqlite database is available and display an error message if the file is not available (`assert` checks if the expression is `True`, otherwise throws `AssertionError` with the error message string provided):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "data_iris_folder_content = os.listdir(\"data/iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_message = \"Error: sqlite file not available, check instructions above to download it\"\n",
    "assert \"database.sqlite\" in data_iris_folder_content, error_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assert statements generally help you locate\n",
    "or identify bugs in your Python programs,\n",
    "as a way of creating such built-in tests.\n",
    "If you do a lot of testing,\n",
    "you'll actually do a lot of assert statements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the Database with the sqlite3 Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQLite\n",
    "comes with your standard Python,\n",
    "so it's not a library that you need to go and install\n",
    "separately,\n",
    "so it's a pretty easy and nice way\n",
    "of interacting with a simple database\n",
    "using simple database queries.\n",
    "<br><br>\n",
    "We can use the `sqlite3` package from the Python standard library to connect to the `sqlite` database and do sqlite operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('data/iris/database.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sqlite3.Cursor"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `sqlite3.Cursor` object is our interface to the database, mostly throught the `execute` method that allows to run any `SQL` query on our database.\n",
    "\n",
    "First of all we can get a list of all the tables saved into the database, this is done by reading the column `name` from the `sqlite_master` metadata table with:\n",
    "\n",
    "    SELECT name FROM sqlite_master\n",
    "    \n",
    "The output of the `execute` method is an iterator that can be used in a `for` loop to print the value of each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iris',)\n"
     ]
    }
   ],
   "source": [
    "for row in cursor.execute(\"SELECT name FROM sqlite_master\"):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a shortcut to directly execute the query and gather the results is the `fetchall` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Iris',)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"SELECT name FROM sqlite_master\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice**: this way of finding the available tables in a database is specific to `sqlite`, other databases like `MySQL` or `PostgreSQL` have different syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can execute standard `SQL` query on the database, `SQL` is a language designed to interact with data stored in a relational database. It has a standard specification, therefore the commands below work on any database.\n",
    "\n",
    "If you need to connect to another database, you would use another package instead of `sqlite3`, for example:\n",
    "\n",
    "* [MySQL Connector](https://dev.mysql.com/doc/connector-python/en/) for MySQL\n",
    "* [Psycopg](http://initd.org/psycopg/docs/install.html) for PostgreSQL\n",
    "* [pymssql](http://pymssql.org/en/stable/) for Microsoft MS SQL\n",
    "\n",
    "then you would connect to the database using specific host, port and authentication credentials but then you could execute the same exact `SQL` statements.\n",
    "\n",
    "Let's take a look for example at the first 3 rows in the Iris table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_data = cursor.execute(\"SELECT * FROM Iris LIMIT 20\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 5.1, 3.5, 1.4, 0.2, 'Iris-setosa'),\n",
       " (2, 4.9, 3, 1.4, 0.2, 'Iris-setosa'),\n",
       " (3, 4.7, 3.2, 1.3, 0.2, 'Iris-setosa'),\n",
       " (4, 4.6, 3.1, 1.5, 0.2, 'Iris-setosa'),\n",
       " (5, 5, 3.6, 1.4, 0.2, 'Iris-setosa'),\n",
       " (6, 5.4, 3.9, 1.7, 0.4, 'Iris-setosa'),\n",
       " (7, 4.6, 3.4, 1.4, 0.3, 'Iris-setosa'),\n",
       " (8, 5, 3.4, 1.5, 0.2, 'Iris-setosa'),\n",
       " (9, 4.4, 2.9, 1.4, 0.2, 'Iris-setosa'),\n",
       " (10, 4.9, 3.1, 1.5, 0.1, 'Iris-setosa'),\n",
       " (11, 5.4, 3.7, 1.5, 0.2, 'Iris-setosa'),\n",
       " (12, 4.8, 3.4, 1.6, 0.2, 'Iris-setosa'),\n",
       " (13, 4.8, 3, 1.4, 0.1, 'Iris-setosa'),\n",
       " (14, 4.3, 3, 1.1, 0.1, 'Iris-setosa'),\n",
       " (15, 5.8, 4, 1.2, 0.2, 'Iris-setosa'),\n",
       " (16, 5.7, 4.4, 1.5, 0.4, 'Iris-setosa'),\n",
       " (17, 5.4, 3.9, 1.3, 0.4, 'Iris-setosa'),\n",
       " (18, 5.1, 3.5, 1.4, 0.3, 'Iris-setosa'),\n",
       " (19, 5.7, 3.8, 1.7, 0.3, 'Iris-setosa'),\n",
       " (20, 5.1, 3.8, 1.5, 0.3, 'Iris-setosa')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(sample_data))\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id',\n",
       " 'SepalLengthCm',\n",
       " 'SepalWidthCm',\n",
       " 'PetalLengthCm',\n",
       " 'PetalWidthCm',\n",
       " 'Species']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[row[0] for row in cursor.description]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is evident that the interface provided by `sqlite3` is low-level, for data exploration purposes we would like to directly import data into a more user friendly library like `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from a database to `pandas`\n",
    "<br><br>\n",
    "We have imported Pandas as pd,\n",
    "and here to a DataFrame object\n",
    "called iris_data,\n",
    "we use the read_sql_query method from Pandas\n",
    "and we give that a sql_query, a select query,\n",
    "SELECT star FROM Iris.\n",
    "Now, you know what that means.\n",
    "And the connection the object.\n",
    "So, through this connection token\n",
    "and the query\n",
    "Pandas knows\n",
    "or the read_sql_query function knows\n",
    "how to get the results of that query\n",
    "and create a DataFrame for us.\n",
    "Let's run these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_data = pd.read_sql_query(\"SELECT * FROM Iris\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                 int64\n",
       "SepalLengthCm    float64\n",
       "SepalWidthCm     float64\n",
       "PetalLengthCm    float64\n",
       "PetalWidthCm     float64\n",
       "Species           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.read_sql_query` takes a `SQL` query and a connection object and imports the data into a `DataFrame`, also keeping the same data types of the database columns. `pandas` provides a lot of the same functionality of `SQL` with a more user-friendly interface.\n",
    "\n",
    "However, `sqlite3` is extremely useful for downselecting data **before** importing them in `pandas`.\n",
    "\n",
    "For example you might have 1 TB of data in a table stored in a database on a server machine. You are interested in working on a subset of the data based on some criterion, unfortunately it would be impossible to first load data into `pandas` and then filter them, therefore we should tell the database to perform the filtering and just load into `pandas` the downsized dataset.\n",
    "<br><br>\n",
    "Here for example,\n",
    "it's the exact same but we are selecting iris_setosa\n",
    "rather than rather than all three species.\n",
    "We have a query that says\n",
    "SELECT star FROM Iris\n",
    "WHERE species is Iris-setosa.\n",
    "So, once we execute this,\n",
    "we'll see that we only have\n",
    "one species in our resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_setosa_data = pd.read_sql_query(\"SELECT * FROM Iris WHERE Species == 'Iris-setosa'\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 6)\n",
      "(150, 6)\n"
     ]
    }
   ],
   "source": [
    "iris_setosa_data\n",
    "print(iris_setosa_data.shape)\n",
    "print(iris_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = pd.read_sql_query(\"SELECT SepalLengthCm, SepalWidthCm, PetalWidthCm, PetalWidthCm FROM Iris\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalWidthCm  PetalWidthCm\n",
       "0              5.1           3.5           0.2           0.2\n",
       "1              4.9           3.0           0.2           0.2\n",
       "2              4.7           3.2           0.2           0.2\n",
       "3              4.6           3.1           0.2           0.2\n",
       "4              5.0           3.6           0.2           0.2\n",
       "5              5.4           3.9           0.4           0.4\n",
       "6              4.6           3.4           0.3           0.3\n",
       "7              5.0           3.4           0.2           0.2\n",
       "8              4.4           2.9           0.2           0.2\n",
       "9              4.9           3.1           0.1           0.1\n",
       "10             5.4           3.7           0.2           0.2\n",
       "11             4.8           3.4           0.2           0.2\n",
       "12             4.8           3.0           0.1           0.1\n",
       "13             4.3           3.0           0.1           0.1\n",
       "14             5.8           4.0           0.2           0.2\n",
       "15             5.7           4.4           0.4           0.4\n",
       "16             5.4           3.9           0.4           0.4\n",
       "17             5.1           3.5           0.3           0.3\n",
       "18             5.7           3.8           0.3           0.3\n",
       "19             5.1           3.8           0.3           0.3\n",
       "20             5.4           3.4           0.2           0.2\n",
       "21             5.1           3.7           0.4           0.4\n",
       "22             4.6           3.6           0.2           0.2\n",
       "23             5.1           3.3           0.5           0.5\n",
       "24             4.8           3.4           0.2           0.2\n",
       "25             5.0           3.0           0.2           0.2\n",
       "26             5.0           3.4           0.4           0.4\n",
       "27             5.2           3.5           0.2           0.2\n",
       "28             5.2           3.4           0.2           0.2\n",
       "29             4.7           3.2           0.2           0.2\n",
       "..             ...           ...           ...           ...\n",
       "120            6.9           3.2           2.3           2.3\n",
       "121            5.6           2.8           2.0           2.0\n",
       "122            7.7           2.8           2.0           2.0\n",
       "123            6.3           2.7           1.8           1.8\n",
       "124            6.7           3.3           2.1           2.1\n",
       "125            7.2           3.2           1.8           1.8\n",
       "126            6.2           2.8           1.8           1.8\n",
       "127            6.1           3.0           1.8           1.8\n",
       "128            6.4           2.8           2.1           2.1\n",
       "129            7.2           3.0           1.6           1.6\n",
       "130            7.4           2.8           1.9           1.9\n",
       "131            7.9           3.8           2.0           2.0\n",
       "132            6.4           2.8           2.2           2.2\n",
       "133            6.3           2.8           1.5           1.5\n",
       "134            6.1           2.6           1.4           1.4\n",
       "135            7.7           3.0           2.3           2.3\n",
       "136            6.3           3.4           2.4           2.4\n",
       "137            6.4           3.1           1.8           1.8\n",
       "138            6.0           3.0           1.8           1.8\n",
       "139            6.9           3.1           2.1           2.1\n",
       "140            6.7           3.1           2.4           2.4\n",
       "141            6.9           3.1           2.3           2.3\n",
       "142            5.8           2.7           1.9           1.9\n",
       "143            6.8           3.2           2.3           2.3\n",
       "144            6.7           3.3           2.5           2.5\n",
       "145            6.7           3.0           2.3           2.3\n",
       "146            6.3           2.5           1.9           1.9\n",
       "147            6.5           3.0           2.0           2.0\n",
       "148            6.2           3.4           2.3           2.3\n",
       "149            5.9           3.0           1.8           1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SepalLengthCm', 'SepalWidthCm', 'PetalWidthCm', 'PetalWidthCm'], dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning on the iris dataset\n",
    "\n",
    "- Framed as a **supervised learning** problem: Predict the species of an iris using the measurements\n",
    "- Famous dataset for machine learning because prediction is **easy**\n",
    "- Learn more about the iris dataset: [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the iris dataset into scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import load_iris function from datasets module\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save \"bunch\" object containing iris dataset and it's attributes\n",
    "iris = load_iris()\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.4  3.7  1.5  0.2]\n",
      " [ 4.8  3.4  1.6  0.2]\n",
      " [ 4.8  3.   1.4  0.1]\n",
      " [ 4.3  3.   1.1  0.1]\n",
      " [ 5.8  4.   1.2  0.2]\n",
      " [ 5.7  4.4  1.5  0.4]\n",
      " [ 5.4  3.9  1.3  0.4]\n",
      " [ 5.1  3.5  1.4  0.3]\n",
      " [ 5.7  3.8  1.7  0.3]\n",
      " [ 5.1  3.8  1.5  0.3]\n",
      " [ 5.4  3.4  1.7  0.2]\n",
      " [ 5.1  3.7  1.5  0.4]\n",
      " [ 4.6  3.6  1.   0.2]\n",
      " [ 5.1  3.3  1.7  0.5]\n",
      " [ 4.8  3.4  1.9  0.2]\n",
      " [ 5.   3.   1.6  0.2]\n",
      " [ 5.   3.4  1.6  0.4]\n",
      " [ 5.2  3.5  1.5  0.2]\n",
      " [ 5.2  3.4  1.4  0.2]\n",
      " [ 4.7  3.2  1.6  0.2]\n",
      " [ 4.8  3.1  1.6  0.2]\n",
      " [ 5.4  3.4  1.5  0.4]\n",
      " [ 5.2  4.1  1.5  0.1]\n",
      " [ 5.5  4.2  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.   3.2  1.2  0.2]\n",
      " [ 5.5  3.5  1.3  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 4.4  3.   1.3  0.2]\n",
      " [ 5.1  3.4  1.5  0.2]\n",
      " [ 5.   3.5  1.3  0.3]\n",
      " [ 4.5  2.3  1.3  0.3]\n",
      " [ 4.4  3.2  1.3  0.2]\n",
      " [ 5.   3.5  1.6  0.6]\n",
      " [ 5.1  3.8  1.9  0.4]\n",
      " [ 4.8  3.   1.4  0.3]\n",
      " [ 5.1  3.8  1.6  0.2]\n",
      " [ 4.6  3.2  1.4  0.2]\n",
      " [ 5.3  3.7  1.5  0.2]\n",
      " [ 5.   3.3  1.4  0.2]\n",
      " [ 7.   3.2  4.7  1.4]\n",
      " [ 6.4  3.2  4.5  1.5]\n",
      " [ 6.9  3.1  4.9  1.5]\n",
      " [ 5.5  2.3  4.   1.3]\n",
      " [ 6.5  2.8  4.6  1.5]\n",
      " [ 5.7  2.8  4.5  1.3]\n",
      " [ 6.3  3.3  4.7  1.6]\n",
      " [ 4.9  2.4  3.3  1. ]\n",
      " [ 6.6  2.9  4.6  1.3]\n",
      " [ 5.2  2.7  3.9  1.4]\n",
      " [ 5.   2.   3.5  1. ]\n",
      " [ 5.9  3.   4.2  1.5]\n",
      " [ 6.   2.2  4.   1. ]\n",
      " [ 6.1  2.9  4.7  1.4]\n",
      " [ 5.6  2.9  3.6  1.3]\n",
      " [ 6.7  3.1  4.4  1.4]\n",
      " [ 5.6  3.   4.5  1.5]\n",
      " [ 5.8  2.7  4.1  1. ]\n",
      " [ 6.2  2.2  4.5  1.5]\n",
      " [ 5.6  2.5  3.9  1.1]\n",
      " [ 5.9  3.2  4.8  1.8]\n",
      " [ 6.1  2.8  4.   1.3]\n",
      " [ 6.3  2.5  4.9  1.5]\n",
      " [ 6.1  2.8  4.7  1.2]\n",
      " [ 6.4  2.9  4.3  1.3]\n",
      " [ 6.6  3.   4.4  1.4]\n",
      " [ 6.8  2.8  4.8  1.4]\n",
      " [ 6.7  3.   5.   1.7]\n",
      " [ 6.   2.9  4.5  1.5]\n",
      " [ 5.7  2.6  3.5  1. ]\n",
      " [ 5.5  2.4  3.8  1.1]\n",
      " [ 5.5  2.4  3.7  1. ]\n",
      " [ 5.8  2.7  3.9  1.2]\n",
      " [ 6.   2.7  5.1  1.6]\n",
      " [ 5.4  3.   4.5  1.5]\n",
      " [ 6.   3.4  4.5  1.6]\n",
      " [ 6.7  3.1  4.7  1.5]\n",
      " [ 6.3  2.3  4.4  1.3]\n",
      " [ 5.6  3.   4.1  1.3]\n",
      " [ 5.5  2.5  4.   1.3]\n",
      " [ 5.5  2.6  4.4  1.2]\n",
      " [ 6.1  3.   4.6  1.4]\n",
      " [ 5.8  2.6  4.   1.2]\n",
      " [ 5.   2.3  3.3  1. ]\n",
      " [ 5.6  2.7  4.2  1.3]\n",
      " [ 5.7  3.   4.2  1.2]\n",
      " [ 5.7  2.9  4.2  1.3]\n",
      " [ 6.2  2.9  4.3  1.3]\n",
      " [ 5.1  2.5  3.   1.1]\n",
      " [ 5.7  2.8  4.1  1.3]\n",
      " [ 6.3  3.3  6.   2.5]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 7.1  3.   5.9  2.1]\n",
      " [ 6.3  2.9  5.6  1.8]\n",
      " [ 6.5  3.   5.8  2.2]\n",
      " [ 7.6  3.   6.6  2.1]\n",
      " [ 4.9  2.5  4.5  1.7]\n",
      " [ 7.3  2.9  6.3  1.8]\n",
      " [ 6.7  2.5  5.8  1.8]\n",
      " [ 7.2  3.6  6.1  2.5]\n",
      " [ 6.5  3.2  5.1  2. ]\n",
      " [ 6.4  2.7  5.3  1.9]\n",
      " [ 6.8  3.   5.5  2.1]\n",
      " [ 5.7  2.5  5.   2. ]\n",
      " [ 5.8  2.8  5.1  2.4]\n",
      " [ 6.4  3.2  5.3  2.3]\n",
      " [ 6.5  3.   5.5  1.8]\n",
      " [ 7.7  3.8  6.7  2.2]\n",
      " [ 7.7  2.6  6.9  2.3]\n",
      " [ 6.   2.2  5.   1.5]\n",
      " [ 6.9  3.2  5.7  2.3]\n",
      " [ 5.6  2.8  4.9  2. ]\n",
      " [ 7.7  2.8  6.7  2. ]\n",
      " [ 6.3  2.7  4.9  1.8]\n",
      " [ 6.7  3.3  5.7  2.1]\n",
      " [ 7.2  3.2  6.   1.8]\n",
      " [ 6.2  2.8  4.8  1.8]\n",
      " [ 6.1  3.   4.9  1.8]\n",
      " [ 6.4  2.8  5.6  2.1]\n",
      " [ 7.2  3.   5.8  1.6]\n",
      " [ 7.4  2.8  6.1  1.9]\n",
      " [ 7.9  3.8  6.4  2. ]\n",
      " [ 6.4  2.8  5.6  2.2]\n",
      " [ 6.3  2.8  5.1  1.5]\n",
      " [ 6.1  2.6  5.6  1.4]\n",
      " [ 7.7  3.   6.1  2.3]\n",
      " [ 6.3  3.4  5.6  2.4]\n",
      " [ 6.4  3.1  5.5  1.8]\n",
      " [ 6.   3.   4.8  1.8]\n",
      " [ 6.9  3.1  5.4  2.1]\n",
      " [ 6.7  3.1  5.6  2.4]\n",
      " [ 6.9  3.1  5.1  2.3]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 6.8  3.2  5.9  2.3]\n",
      " [ 6.7  3.3  5.7  2.5]\n",
      " [ 6.7  3.   5.2  2.3]\n",
      " [ 6.3  2.5  5.   1.9]\n",
      " [ 6.5  3.   5.2  2. ]\n",
      " [ 6.2  3.4  5.4  2.3]\n",
      " [ 5.9  3.   5.1  1.8]]\n"
     ]
    }
   ],
   "source": [
    "# print the iris data\n",
    "print(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning terminology\n",
    "\n",
    "- Each row is an **observation** (also known as: sample, example, instance, record)\n",
    "- Each column is a **feature** (also known as: predictor, attribute, independent variable, input, regressor, covariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# print the names of the four features\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# print integers representing the species of each observation\n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# print the encoding scheme for species: 0 = setosa, 1 = versicolor, 2 = virginica\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each value we are predicting is the **response** (also known as: target, outcome, label, dependent variable)\n",
    "- **Classification** is supervised learning in which the response is categorical\n",
    "- **Regression** is supervised learning in which the response is ordered and continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements for working with data in scikit-learn\n",
    "\n",
    "First step in ML, is for the model to learn the relationship between the features and the response/target. We will do this part later, but first we need to make sure the features and response are in the form that scikit learn expects. There are four key requirements to keep in mind which are as follows:\n",
    "\n",
    "1. Features and response are **separate objects**\n",
    "2. Features and response should be **numeric**\n",
    "3. Features and response should be **NumPy arrays**\n",
    "4. Features and response should have **specific shapes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# check the types of the features and response\n",
    "print(type(iris.data))\n",
    "print(type(iris.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "# check the shape of the features first (first dimension = number of observations, second dimensions = number of features)\n",
    "print(iris.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the response object is expected to have a single dimension should have the same magnitude as the first dimension of the feature object. In other words, there should be one response corresponding to each observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "# check the shape of the response (single dimension matching the number of observations)\n",
    "print(iris.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store feature matrix in \"X\"\n",
    "X = iris.data\n",
    "\n",
    "# store response vector in \"y\"\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- scikit-learn documentation: [Dataset loading utilities](http://scikit-learn.org/stable/datasets/)\n",
    "- Jake VanderPlas: Fast Numerical Computing with NumPy ([slides](https://speakerdeck.com/jakevdp/losing-your-loops-fast-numerical-computing-with-numpy-pycon-2015), [video](https://www.youtube.com/watch?v=EEUXKG97YRw))\n",
    "- Scott Shell: [An Introduction to NumPy](http://www.engr.ucsb.edu/~shell/che210d/numpy.pdf) (PDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors (KNN) classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Pick a value for K.\n",
    "2. Search for the K observations in the training data that are \"nearest\" to the measurements of the unknown iris.\n",
    "3. Use the most popular response value from the K nearest neighbors as the predicted response value for the unknown iris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example training data\n",
    "\n",
    "![Training data](images/04_knn_dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classification map (K=1)\n",
    "\n",
    "![1NN classification map](images/04_1nn_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classification map (K=5)\n",
    "\n",
    "![5NN classification map](images/04_5nn_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn 4-step modeling pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Import the class you plan to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** \"Instantiate\" the \"estimator\"\n",
    "\n",
    "- \"Estimator\" is scikit-learn's term for model\n",
    "- \"Instantiate\" means \"make an instance of\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Name of the object does not matter\n",
    "- Can specify tuning parameters (aka \"hyperparameters\") during this step\n",
    "- All parameters not specified are set to their defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "print(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Fit the model with data (aka \"model training\")\n",
    "\n",
    "- Model is learning the relationship between X and y\n",
    "- Occurs in-place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Predict the response for a new observation\n",
    "\n",
    "- New observations are called \"out-of-sample\" data\n",
    "- Uses the information it learned during the model training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict([[3, 5, 4, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it predicted 2, which represents virginica species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Returns a NumPy array\n",
    "- Can predict for multiple observations at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = [[3, 5, 4, 2], [5, 4, 3, 2]]\n",
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the model predicted 2 and 1 which is virginica and versicolor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a different value for K\n",
    "<br><br>\n",
    "This is known as model tuning. Here we are varying the arguments that we passed to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the model (using the value k-5)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# fit the model with data\n",
    "knn.fit(X, y)\n",
    "\n",
    "# predict the response for new observations\n",
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a different classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X, y)\n",
    "\n",
    "# predict the response for new observations\n",
    "logreg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model produced the correct predictions for these two unknown irises? The answer is that we don't know because they are out of sample observations  meaning that we don't know the true response values. \n",
    "<br><br>\n",
    "Our goal in supervised ML is to build models that generalize to new data. However, we often aren't able to truly measure how well our models will perform on out-of-sample data. Does that mean we're forced to just guess how well our models are likely to do? Thankfully no. Later you will see model evaluation procedures which allow us to estimate how well our models are likely to perform on out-of-sample data using our existing labelled data. These procedures will help us to choose which value of K is best for kNN and to choose whether kNN or logistic regression is a better choice for our particular task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [Nearest Neighbors](http://scikit-learn.org/stable/modules/neighbors.html) (user guide), [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) (class documentation)\n",
    "- [Logistic Regression](http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression) (user guide), [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) (class documentation)\n",
    "- [Videos from An Introduction to Statistical Learning](http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/)\n",
    "    - Classification Problems and K-Nearest Neighbors (Chapter 2)\n",
    "    - Introduction to Classification (Chapter 4)\n",
    "    - Logistic Regression and Maximum Likelihood (Chapter 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- How do I choose **which model to use** for my supervised learning task?\n",
    "- How do I choose the **best tuning parameters** for that model?\n",
    "- How do I estimate the **likely performance of my model** on out-of-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "- Classification task: Predicting the species of an unknown iris\n",
    "- Used three classification models: KNN (K=1), KNN (K=5), logistic regression\n",
    "- Need a way to choose between the models\n",
    "\n",
    "The goal of supervised learning is always to build a model that generalizes to our sample data and that's what we really need is a procedure that allows us to estimate how well a given model is likely to perform on out-of-sample data. This is known as Model Evaluation Procedures. If we can estimate the likeyl performance of our three models then we can use that performance estimate to choose between the models.\n",
    "\n",
    "**Solution:** Model evaluation procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation procedure #1: Train and test on the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train the model on the **entire dataset**.\n",
    "2. Test the model on the **same dataset**, and evaluate how well we did by comparing the **predicted** response values with the **true** response values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the iris data\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# create X (features) and y (response)\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logisitc Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X, y)\n",
    "\n",
    "# predict the response values for the observations in X\n",
    "logreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the predicted response values\n",
    "y_pred = logreg.predict(X)\n",
    "\n",
    "# check how many predictions were generated\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification accuracy:\n",
    "\n",
    "- **Proportion** of correct predictions\n",
    "- Common **evaluation metric** for classification problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we import the metrics module then we use the accuracy score function and pass it the true response values followed by the predicted response values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n"
     ]
    }
   ],
   "source": [
    "# compute classification accuracy for the logistic regression model\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "returned 0.96. That means that it compared the 150 true responses/targets with the corresponding 150 predicted responses and calculated that 96% of our predictions were correct. This is known as our training accuracy because we are training the model on the same data we used to train the model. \n",
    "- Known as **training accuracy** when you train and test the model on the same data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN (K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X, y)\n",
    "y_pred = knn.predict(X)\n",
    "print(metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.96666 is slightly better than logisitic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN (K=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X, y)\n",
    "y_pred = knn.predict(X)\n",
    "print(metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100% accurate. So we would conclude that KNN (K=1) is the best model to use with this data OR would we draw that conclusion?\n",
    "\n",
    "However, this doesn't work b/c training and testing your models on the same data is not a useful procedure for deciding whic model to choose. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with training and testing on the same data\n",
    "\n",
    "- Goal is to estimate likely performance of a model on **out-of-sample data**\n",
    "- But, maximizing training accuracy rewards **overly complex models** that won't necessarily generalize\n",
    "    - in other words, models with a high training accuracy may not actually do well when making predictions on out-of-sample data\n",
    "- Unnecessarily complex models **overfit** the training data\n",
    "    - models that overfit have learned the noise in the data rather than the signal.\n",
    "    - in the case of KNN, a very low value of K, creates a high complexity model because it follows the noise in the data. The diagram below expalins overfitting quite well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Overfitting](images/05_overfitting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation procedure #2: Train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Split the dataset into two pieces: a **training set** and a **testing set**.\n",
    "2. Train the model on the **training set**.\n",
    "3. Test the model on the **testing set**, and evaluate how well we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "# print the shapes of X and y\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the test_size parameter decides the proportion of observations assigned to the testing set. In this case, I've assigned 40% of observations to the testing set which means that 60% will be assigned to the training set. There is no general rule to what percentage is best, but people generarlly use between 20 and 40 of their data for testing. In terms of how the observations are assigned, it's actually a random process. You'll find that if you run this function 5 different times on the same set of data it will split the data 5 different ways. However, if you use an optional parameter called \"random_state\" and give it an integer value it will split a given data set the same exact way every single time. I'm going to use random_state=4, and my data will be split exactly the same way everytime. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Train/test split](images/05_train_test_split.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did this accomplish?\n",
    "\n",
    "- Model can be trained and tested on **different data**\n",
    "- Response values are known for the testing set, and thus **predictions can be evaluated**\n",
    "- **Testing accuracy** is a better estimate than training accuracy of out-of-sample performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4)\n",
      "(60, 4)\n"
     ]
    }
   ],
   "source": [
    "# print the shapes of the new X objects\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90,)\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "# print the shapes of the new y objects\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 2: train the model on the training set\n",
    "logreg = LogisticRegression() # instantiate logisitic regression model\n",
    "logreg.fit(X_train, y_train) # fit it x train and y train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: make predictions on the testing set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# compare actual responses response values (y_test) with predicted response values (y_pred)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for KNN with K=5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for KNN with K=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we locate an even better value for K?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've written a for loop to do exactly that in which I try every value of K from 1 through 25 and then record KNN's testing accuracy in this python list called scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try K=1 through k=25 and record testing accuracy\n",
    "k_range = range(1, 26)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    scores.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Testing Accuracy')"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhsQwDMMIhRkSwzAMIxRmSAzDMIxQ/G8wmBXpWyk0+wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0eb1b748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import Matplotlib (scientific plotting library)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# allow plots to appear within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# plot the relationship between K and testing accuracy\n",
    "plt.plot(k_range, scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Testing Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in general, as the value of K increases, there appears to be a rise in the testing accuracy and then a fall. This rise and fall is actually quite typical when examining the relationship between model complexity and testing accuracy. As we talked about earlier, training accuracy rises as model complexicity increases and the model for KNN is deteremined by the value of K. Testing accuracy on the other hand, penalizes models that are too complex and models that aren't complex enough. Therefore, you'll see maximum testing accuracy when the model has the right level of complexity. In this case, we see the highest accuracy from K=6 through K=17 and we would tentatively conclude that K value in that range would be better than K=5. However, b/c this data set is so small and b/c this is such an esasy classification task, it's hard to reliably say whether this behavior we are seeing in this one plot will indeed generalize. Regardless, plotting testing accuracy vs. model complexity is a very useful way to tune any parameters that relate to model complexity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Training accuracy** rises as model complexity increases\n",
    "- **Testing accuracy** penalizes models that are too complex or not complex enough\n",
    "- For KNN models, complexity is determined by the **value of K** (lower value = more complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions on out-of-sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've chosen a model and it's optimal parameters and are ready to make predictions on out-of-sample data, it's important that you retrain your model on all of the available training data. Otherwise, you'll be throwing away valualble training data. In this case, we will choose the value of 11 for K since that was in the middle of the K range with the highest testing accuracy and we'll call that our best model. Thus, we instantiate the KNN model with n_neighbors=11 and we fit the model with x and y and use the model to make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the model with the best known parameters\n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "\n",
    "# train the model with X and y (not X_train and y_train)\n",
    "knn.fit(X, y)\n",
    "\n",
    "# make a prediction for an out-of-sample observation\n",
    "knn.predict([[3, 5, 4, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsides of train/test split?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Provides a **high-variance estimate** of out-of-sample accuracy\n",
    "    - meaning that it can change a lot depending on which observations happen to be in the training set versus the testing set.\n",
    "- **K-fold cross-validation** overcomes this limitation by repeating the train_test_split process multiple times in a systematic way and averaging the results. We'll go over that procedure in a future video.\n",
    "- But, train/test split is still useful because of its **flexibility and speed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- Quora: [What is an intuitive explanation of overfitting?](http://www.quora.com/What-is-an-intuitive-explanation-of-overfitting/answer/Jessica-Su)\n",
    "- Video: [Estimating prediction error](https://www.youtube.com/watch?v=_2ij6eaaSl0&t=2m34s) (12 minutes, starting at 2:34) by Hastie and Tibshirani\n",
    "- [Understanding the Bias-Variance Tradeoff](http://scott.fortmann-roe.com/docs/BiasVariance.html)\n",
    "    - [Guiding questions](https://github.com/justmarkham/DAT8/blob/master/homework/09_bias_variance.md) when reading this article\n",
    "- Video: [Visualizing bias and variance](http://work.caltech.edu/library/081.html) (15 minutes) by Abu-Mostafa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
